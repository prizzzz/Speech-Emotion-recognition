{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPWKEJjFfhYxGPMACTOMSge"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1F9x8updzjGH","executionInfo":{"status":"ok","timestamp":1744145584181,"user_tz":-330,"elapsed":6280,"user":{"displayName":"Priyanka Chougule","userId":"00625398433204085615"}},"outputId":"2f8fccfe-6123-40e7-8a98-3acdfa739240"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n"]},{"cell_type":"code","source":["base_path = \"/content/drive/MyDrive/SER_yt\"\n","import os\n","os.makedirs(base_path, exist_ok=True)"],"metadata":{"id":"Z-XUF6ek04t9","executionInfo":{"status":"ok","timestamp":1744145732808,"user_tz":-330,"elapsed":39,"user":{"displayName":"Priyanka Chougule","userId":"00625398433204085615"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor\n","import torch\n","import librosa\n","import numpy as np\n","import torch.nn.functional as F\n","\n","# Load your saved model and processor\n","model_path = \"/content/drive/MyDrive/SER_yt/my_saved_model\"\n","model = Wav2Vec2ForSequenceClassification.from_pretrained(model_path)\n","processor = Wav2Vec2Processor.from_pretrained(model_path)\n","model.eval()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2xJnGECY1Qmk","executionInfo":{"status":"ok","timestamp":1744145736021,"user_tz":-330,"elapsed":1112,"user":{"displayName":"Priyanka Chougule","userId":"00625398433204085615"}},"outputId":"a111839a-9fdb-4fd8-db87-138c291a280a"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Wav2Vec2ForSequenceClassification(\n","  (wav2vec2): Wav2Vec2Model(\n","    (feature_extractor): Wav2Vec2FeatureEncoder(\n","      (conv_layers): ModuleList(\n","        (0): Wav2Vec2GroupNormConvLayer(\n","          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n","          (activation): GELUActivation()\n","          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n","        )\n","        (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n","          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n","          (activation): GELUActivation()\n","        )\n","        (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n","          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n","          (activation): GELUActivation()\n","        )\n","      )\n","    )\n","    (feature_projection): Wav2Vec2FeatureProjection(\n","      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (projection): Linear(in_features=512, out_features=768, bias=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): Wav2Vec2Encoder(\n","      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n","        (conv): ParametrizedConv1d(\n","          768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n","          (parametrizations): ModuleDict(\n","            (weight): ParametrizationList(\n","              (0): _WeightNorm()\n","            )\n","          )\n","        )\n","        (padding): Wav2Vec2SamePadLayer()\n","        (activation): GELUActivation()\n","      )\n","      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","      (layers): ModuleList(\n","        (0-11): 12 x Wav2Vec2EncoderLayer(\n","          (attention): Wav2Vec2SdpaAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (feed_forward): Wav2Vec2FeedForward(\n","            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n","            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (output_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (projector): Linear(in_features=768, out_features=256, bias=True)\n","  (classifier): Linear(in_features=256, out_features=7, bias=True)\n",")"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["# Corrected label map\n","id2label = {\n","    0: \"happy\",\n","    1: \"neutral\",\n","    2: \"sad\",\n","    3: \"fear\",\n","    4: \"disgust\",\n","    5: \"ps\",\n","    6: \"angry\"\n","}"],"metadata":{"id":"jl0n719s1hNn","executionInfo":{"status":"ok","timestamp":1744145739557,"user_tz":-330,"elapsed":39,"user":{"displayName":"Priyanka Chougule","userId":"00625398433204085615"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","def predict_emotion(audio_path):\n","    # Load and preprocess the audio\n","    speech, sr = librosa.load(audio_path, sr=16000)\n","\n","    # Pad or trim the audio to 2 seconds (32000 samples)\n","    speech = speech[:32000] if len(speech) > 32000 else np.pad(speech, (0, 32000 - len(speech)), mode='constant')\n","\n","    # Process with processor\n","    inputs = processor(speech, sampling_rate=16000, return_tensors=\"pt\")\n","\n","    # Predict\n","    with torch.no_grad():\n","        logits = model(**inputs).logits\n","        probs = F.softmax(logits, dim=-1)\n","\n","    predicted_id = torch.argmax(probs, dim=-1).item()\n","    confidence = torch.max(probs).item()\n","\n","    return id2label[predicted_id], round(confidence * 100, 2)\n"],"metadata":{"id":"PEdfi33L1o-T","executionInfo":{"status":"ok","timestamp":1744145763525,"user_tz":-330,"elapsed":16,"user":{"displayName":"Priyanka Chougule","userId":"00625398433204085615"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Test on sample audio\n","test_audio_path = \"/content/drive/MyDrive/SER_yt/Dataset/TESS Toronto emotional speech set data/YAF_sad/YAF_wife_sad.wav\"\n","emotion, confidence = predict_emotion(test_audio_path)\n","print(f\"Predicted Emotion: {emotion} (Confidence: {confidence}%)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ShTy03Q4Hf0","executionInfo":{"status":"ok","timestamp":1744145808701,"user_tz":-330,"elapsed":1488,"user":{"displayName":"Priyanka Chougule","userId":"00625398433204085615"}},"outputId":"d47f5248-9bb9-452a-f37f-9a824b0ab276"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Emotion: sad (Confidence: 86.87%)\n"]}]},{"cell_type":"code","source":["import os\n","import random\n","\n","dataset_root = \"/content/drive/MyDrive/SER_yt/Dataset/TESS Toronto emotional speech set data\"\n","\n","# Gather all .wav file paths recursively\n","all_audio_files = []\n","for root, dirs, files in os.walk(dataset_root):\n","    for file in files:\n","        if file.endswith(\".wav\"):\n","            all_audio_files.append(os.path.join(root, file))\n","\n","# Choose one random file\n","random_audio_path = random.choice(all_audio_files)\n","\n","# Predict emotion\n","emotion, confidence = predict_emotion(random_audio_path)\n","print(f\"Random File: {os.path.basename(random_audio_path)}\")\n","print(f\"Predicted Emotion: {emotion} (Confidence: {confidence}%)\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UQyKy-cyNCmE","executionInfo":{"status":"ok","timestamp":1744146024490,"user_tz":-330,"elapsed":1098,"user":{"displayName":"Priyanka Chougule","userId":"00625398433204085615"}},"outputId":"d2416749-b4f5-4e66-d9c1-98afedd9c5d7"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Random File: OAF_dog_fear.wav\n","Predicted Emotion: fear (Confidence: 86.92%)\n"]}]}]}